
   /* @RequiresApi(Build.VERSION_CODES.N)
    override fun analyze(image: ImageProxy?, rotationDegrees: Int) {
        var lastAnalyzedTimestamp = 0L

        uiCoroutineScope.launch {
            val localModel =
                FirebaseCustomLocalModel.Builder().setAssetFilePath(MODEL_PATH_LOCAL).build()
            _interpreter.value = createInterpreter(localModel)
            val inputOutputOptions = createInputOutputOptions()
            val labelList: MutableList<String> = mutableListOf()


            val currentTimestamp = System.currentTimeMillis()
            if (currentTimestamp - lastAnalyzedTimestamp >=
                TimeUnit.SECONDS.toMillis(1)
            ) {
                lastAnalyzedTimestamp = currentTimestamp
            }

            *//*The ImageProxy object sent into the analyze() method contains information about our latest image in YUV format.
        This means the image is broken into three planes: the first is a measure of brightness, and the second and third are measures of color in the red and blue space.
        We can retrieve these three planes like so*//*
            val y = image?.planes?.get(0)
            val u = image?.planes?.get(1)
            val v = image?.planes?.get(2)

            *//*get the remining buffers from each plane*//*
            val numOfPixelsInY = y?.buffer?.remaining()
            val numOfPixelsInU = u?.buffer?.remaining()
            val numOfPixelsInV = v?.buffer?.remaining()

            *//*convert them into a singe YUV formatted ByteArray*//*
            val imageDataYUV = ByteArray(numOfPixelsInY!! + numOfPixelsInU!! + numOfPixelsInV!!)

            y.buffer.get(imageDataYUV, 0, numOfPixelsInY)
            u.buffer.get(imageDataYUV, 0, numOfPixelsInU)
            v.buffer.get(imageDataYUV, 0, numOfPixelsInV)

            val inputs = FirebaseModelInputs.Builder()
                .add(imageDataYUV)
                .build()

            Log.i("$TAG ðŸ™„ðŸ™„ðŸ™„", _interpreter.value.toString())
            _interpreter.value?.run(inputs, inputOutputOptions)
                ?.addOnSuccessListener {
                    try {
                        BufferedReader(
                            InputStreamReader(Application().resources.assets.open(LABEL_NAME))
                        ).use { reader ->
                            var line = reader.readLine()
                            while (line != null) {
                                labelList.add(line)
                                line = reader.readLine()
                            }
                        }
                    } catch (e: IOException) {
                        Log.e(TAG, "couldnt read the labels", e)
                    }
                }
        }
    }*/


     /*fun convertBitmapToByteByffer(bitmap: Bitmap): ByteBuffer {

         if (imgData == null){
             return
         }
         *//*re reading the buffer and cleaning the old one *//*
         imgData.rewind()

         bitmap.getPixels(intValues, 0, 0 ,0,0, bitmap.width, bitmap.height)

         val pixel = 0
         val startTime = SystemClock.uptimeMillis()

         for(widthReader in  0 until  DIM_IMG_SIZE_X){
             for (heightReader in 0 until DIM_IMG_SIZE_Y){
                 val valuesHolder = intValues[pixel.plus(1)]
                 imgData.putFloat((((valuesHolder shr 16 and 0xFF) - IMAGE_MEAN)/ IMAGE_STRIDE))
                 imgData.putFloat((((valuesHolder shr 8 and 0xFF) - IMAGE_MEAN)/ IMAGE_STRIDE))
                 imgData.putFloat((((valuesHolder  and 0xFF) - IMAGE_MEAN)/ IMAGE_STRIDE))
             }
         }
         val endTime = SystemClock.uptimeMillis()

     }
*/

//2



    /* fun convertImageProxyToBitmap(image: ImageProxy): Bitmap {

         val yBuffer = image.planes[0].buffer // Y
         val uBuffer = image.planes[1].buffer // U
         val vBuffer = image.planes[2].buffer // V

         val ySize = yBuffer.remaining()
         val uSize = uBuffer.remaining()
         val vSize = vBuffer.remaining()

         val nv21 = ByteArray(ySize + uSize + vSize)

         //U and V are swapped
         yBuffer.get(nv21, 0, ySize)
         vBuffer.get(nv21, ySize, vSize)
         uBuffer.get(nv21, ySize + vSize, uSize)

         val yuvImage = YuvImage(nv21, ImageFormat.NV21, image.width, image.height, null)
         val out = ByteArrayOutputStream()
         yuvImage.compressToJpeg(Rect(0, 0, yuvImage.width, yuvImage.height), 100, out)
         val imageBytes = out.toByteArray()
         return BitmapFactory.decodeByteArray(imageBytes, 0, imageBytes.size)
     }

     fun classifyFrame(bitmap: Bitmap): List<String> {

         val topLabels = mutableListOf<String>()

         _interpreter.value?.let {
             _interpreter.value = createInterpreter()
             val input = bitmapToInputArray()
             val inputOutputOptions = createInputOutputOptions()
             val labelList: ArrayList<String>? = null

             val inputs = FirebaseModelInputs.Builder()
                 .add(input)
                 .build()

             Log.i("$TAG_MODEL_STATEðŸ™„ðŸ™„ðŸ™„", _interpreter.value.toString())

             _interpreter.value?.run(inputs, inputOutputOptions)
                 ?.addOnSuccessListener {
                     try {
                         BufferedReader(
                             InputStreamReader(Application().resources.assets.open(LABEL_NAME))
                         ).use { reader ->
                             var line = reader.readLine()
                             while (line != null) {
                                 labelList?.add(line)
                                 line = reader.readLine()
                             }
                         }
                     } catch (e: IOException) {
                         Log.e("$TAG_MODEL_STATEðŸ˜¥ðŸ˜¥ðŸ˜¥", "couldnt read the labels", e)
                     }
                 }
             val startTime = SystemClock.uptimeMillis()
         }
         return topLabels
     }
 */